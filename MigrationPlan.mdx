# Toronto Pulse: Architecture Migration Plan

## Executive Summary

This document outlines the complete migration plan to transform Toronto Pulse from its current monolithic data service architecture to a scalable, plugin-based, domain-driven architecture. The migration is designed to be incremental, low-risk, and allow for continuous operation during the transition.

**Timeline**: 6-8 weeks
**Risk Level**: Low (incremental approach)
**Downtime**: Zero (parallel development)

---

## Current State Analysis

### Current Architecture Strengths
- ✅ Well-structured TypeScript codebase
- ✅ Clean separation between UI and data layers
- ✅ Functional React patterns with hooks
- ✅ Mapbox integration working well
- ✅ TTC data integration fully functional
- ✅ Caching mechanism in place
- ✅ Type safety with TypeScript interfaces

### Current Architecture Limitations
- ❌ Monolithic `DataService` class requires code changes for each new source
- ❌ Hard-coded layer configurations in `layers.ts`
- ❌ Manual GeoJSON transformation for each data type
- ❌ No standardized error handling across different API types
- ❌ Limited observability and monitoring
- ❌ Tight coupling between data sources and UI components
- ❌ No plugin system for extensibility
- ❌ Missing data validation and quality checks
- ❌ No CLI tools for development workflow

### Technical Debt Assessment
- **High Priority**: Data service refactoring
- **Medium Priority**: Layer configuration system
- **Low Priority**: UI component structure (already well-designed)

---

## Target State Architecture

### New Directory Structure
```
src/
├── domains/                    # NEW: Business domains
│   ├── transportation/
│   │   ├── ttc-vehicles/
│   │   ├── bike-share/
│   │   └── go-transit/
│   ├── infrastructure/
│   │   ├── road-restrictions/
│   │   ├── construction/
│   │   └── utilities/
│   ├── environment/
│   │   ├── beach-quality/
│   │   ├── air-quality/
│   │   └── weather/
│   └── events/
│       ├── festivals/
│       └── emergencies/
├── core/                       # NEW: Shared kernel
│   ├── data-sources/
│   │   ├── registry.ts
│   │   ├── base-plugin.ts
│   │   ├── transformers/
│   │   └── validators/
│   ├── mapbox/
│   │   ├── layer-renderer.ts
│   │   └── interaction-handler.ts
│   ├── ui/
│   │   ├── components/
│   │   └── hooks/
│   ├── cache/
│   │   ├── strategies.ts
│   │   └── storage.ts
│   └── utils/
├── infrastructure/             # NEW: External concerns
│   ├── apis/
│   │   ├── toronto-open-data.ts
│   │   ├── socrata.ts
│   │   └── ckan.ts
│   ├── config/
│   │   ├── feature-flags.ts
│   │   └── environment.ts
│   └── monitoring/
│       ├── metrics.ts
│       └── health-checks.ts
├── app/                        # EXISTING: Application layer
│   ├── components/             # Keep existing
│   ├── hooks/                  # Keep existing
│   └── store/                  # NEW: Global state
└── tools/                      # NEW: CLI and dev tools
    ├── cli/
    ├── generators/
    └── validators/
```

---

## Migration Strategy

### Phase 1: Foundation Setup (Week 1-2)
**Goal**: Establish core infrastructure without breaking existing functionality

#### Step 1.1: Create Core Infrastructure (Day 1-2)
1. **Create new directory structure**
   ```bash
   mkdir -p src/core/{data-sources,mapbox,ui,cache,utils}
   mkdir -p src/domains/{transportation,infrastructure,environment,events}
   mkdir -p src/infrastructure/{apis,config,monitoring}
   mkdir -p src/tools/{cli,generators,validators}
   ```

2. **Install additional dependencies**
   ```bash
   npm install zod commander inquirer chalk ora
   npm install -D @types/inquirer
   ```

3. **Create base interfaces and types**
   ```typescript
   // src/core/data-sources/types.ts
   export interface DataSourcePlugin {
     metadata: DataSourceMetadata;
     fetcher: DataFetcher;
     transformer: DataTransformer;
     validator: DataValidator;
     cacheStrategy?: CacheStrategy;
   }
   
   export interface DataSourceMetadata {
     id: string;
     name: string;
     domain: string;
     version: string;
     description: string;
     refreshInterval: number;
     reliability: 'high' | 'medium' | 'low';
   }
   
   // ... rest of interfaces
   ```

#### Step 1.2: Implement Data Source Registry (Day 3-4)
1. **Create plugin registry**
   ```typescript
   // src/core/data-sources/registry.ts
   class DataSourceRegistry {
     private sources = new Map<string, DataSourcePlugin>();
     
     register(plugin: DataSourcePlugin): void {
       this.sources.set(plugin.metadata.id, plugin);
     }
     
     get(id: string): DataSourcePlugin | undefined {
       return this.sources.get(id);
     }
     
     getByDomain(domain: string): DataSourcePlugin[] {
       return Array.from(this.sources.values())
         .filter(source => source.metadata.domain === domain);
     }
     
     getAll(): DataSourcePlugin[] {
       return Array.from(this.sources.values());
     }
   }
   ```

2. **Create base plugin class**
   ```typescript
   // src/core/data-sources/base-plugin.ts
   export abstract class BaseDataSourcePlugin implements DataSourcePlugin {
     abstract metadata: DataSourceMetadata;
     abstract fetcher: DataFetcher;
     abstract transformer: DataTransformer;
     abstract validator: DataValidator;
     
     async fetchData(): Promise<GeoJSONFeatureCollection> {
       const rawData = await this.fetcher.fetch();
       const validData = this.validator.validate(rawData);
       return this.transformer.transform(validData);
     }
   }
   ```

#### Step 1.3: Create Universal Transformers (Day 5-6)
1. **Implement base transformer interfaces**
   ```typescript
   // src/core/data-sources/transformers/base.ts
   export interface DataTransformer {
     transform(data: any): GeoJSONFeatureCollection;
   }
   
   export interface TransformConfig {
     latField: string;
     lonField: string;
     idField: string;
     properties: Record<string, string>;
   }
   ```

2. **Create common transformers**
   ```typescript
   // src/core/data-sources/transformers/json-to-geojson.ts
   export class JSONToGeoJSONTransformer implements DataTransformer {
     constructor(private config: TransformConfig) {}
     
     transform(data: any): GeoJSONFeatureCollection {
       // Implementation for JSON to GeoJSON conversion
     }
   }
   
   // Similar for XML, CSV, GTFS, etc.
   ```

#### Step 1.4: Setup Configuration Schema (Day 7-8)
1. **Create Zod schemas**
   ```typescript
   // src/core/data-sources/schemas.ts
   import { z } from 'zod';
   
   export const DataSourceConfigSchema = z.object({
     metadata: z.object({
       id: z.string(),
       name: z.string(),
       domain: z.enum(['transportation', 'infrastructure', 'environment', 'events']),
       version: z.string(),
       refreshInterval: z.number().min(1000),
       reliability: z.enum(['high', 'medium', 'low']),
     }),
     api: z.object({
       type: z.enum(['json', 'xml', 'csv', 'gtfs', 'custom']),
       baseUrl: z.string().url(),
       authentication: z.optional(z.object({
         type: z.enum(['apikey', 'oauth', 'basic']),
         config: z.record(z.string())
       }))
     }),
     transform: z.object({
       strategy: z.string(),
       mappings: z.record(z.string())
     })
   });
   ```

#### Step 1.5: Enhanced Caching System (Day 9-10)
1. **Create cache strategies**
   ```typescript
   // src/core/cache/strategies.ts
   export interface CacheStrategy {
     key: string;
     ttl: number;
     storage: 'memory' | 'indexeddb' | 'localstorage';
     invalidationRules: string[];
   }
   
   export class CacheManager {
     private strategies = new Map<string, CacheStrategy>();
     
     async get<T>(key: string): Promise<T | null> {
       // Implementation
     }
     
     async set<T>(key: string, value: T, strategy?: string): Promise<void> {
       // Implementation
     }
   }
   ```

**Phase 1 Testing & Validation**
- Unit tests for all new core classes
- Integration tests for registry and caching
- No existing functionality affected

---

### Phase 2: Migrate Existing TTC Data Source (Week 3)
**Goal**: Convert TTC data source to new plugin architecture as proof of concept

#### Step 2.1: Create TTC Plugin Structure (Day 1-2)
1. **Create TTC plugin directory**
   ```bash
   mkdir -p src/domains/transportation/ttc-vehicles
   ```

2. **Create TTC plugin configuration**
   ```json
   // src/domains/transportation/ttc-vehicles/config.json
   {
     "metadata": {
       "id": "ttc-vehicles",
       "name": "TTC Live Vehicles",
       "domain": "transportation",
       "version": "1.0.0",
       "description": "Real-time bus and streetcar positions via TTC XML API",
       "refreshInterval": 30000,
       "reliability": "high",
       "tags": ["transit", "real-time", "toronto"],
       "author": "Toronto Pulse Team",
       "dataLicense": "Open Government License - Ontario"
     },
     "api": {
       "type": "xml",
       "baseUrl": "https://webservices.umoiq.com/service/publicXMLFeed",
       "authentication": null,
       "rateLimit": {
         "requests": 60,
         "window": 60000
       },
       "timeout": 10000
     },
     "transform": {
       "strategy": "ttc-xml-custom",
       "mappings": {
         "latitude": "@lat",
         "longitude": "@lon",
         "id": "@id",
         "route": "@routeTag",
         "direction": "@dirTag",
         "heading": "@heading",
         "speed": "@speedKmHr"
       }
     },
     "visualization": {
       "layer": {
         "type": "circle",
         "paint": {
           "circle-radius": 6,
           "circle-color": [
             "case",
             ["==", ["get", "vehicle_type"], "streetcar"], "#dc2626",
             ["==", ["get", "vehicle_type"], "bus"], "#2563eb",
             "#6b7280"
           ],
           "circle-stroke-width": 2,
           "circle-stroke-color": "#ffffff"
         }
       },
       "popup": {
         "template": "ttc-vehicle-popup"
       }
     },
     "cache": {
       "strategy": "real-time",
       "ttl": 30000,
       "storage": "memory"
     }
   }
   ```

#### Step 2.2: Implement TTC Plugin Classes (Day 3-4)
1. **Create TTC fetcher**
   ```typescript
   // src/domains/transportation/ttc-vehicles/fetcher.ts
   export class TTCFetcher implements DataFetcher {
     async fetch(): Promise<any> {
       // Move existing TTC fetching logic here
     }
   }
   ```

2. **Create TTC transformer**
   ```typescript
   // src/domains/transportation/ttc-vehicles/transformer.ts
   export class TTCTransformer implements DataTransformer {
     transform(data: any): GeoJSONFeatureCollection {
       // Move existing TTC transformation logic here
     }
   }
   ```

3. **Create TTC validator**
   ```typescript
   // src/domains/transportation/ttc-vehicles/validator.ts
   export class TTCValidator implements DataValidator {
     validate(data: any): any {
       // Implement data validation logic
     }
   }
   ```

4. **Create main TTC plugin**
   ```typescript
   // src/domains/transportation/ttc-vehicles/index.ts
   export class TTCVehiclesPlugin extends BaseDataSourcePlugin {
     metadata = {
       id: 'ttc-vehicles',
       name: 'TTC Live Vehicles',
       domain: 'transportation',
       // ... from config.json
     };
     
     fetcher = new TTCFetcher();
     transformer = new TTCTransformer();
     validator = new TTCValidator();
   }
   ```

#### Step 2.3: Create Plugin Loader (Day 5)
1. **Implement dynamic plugin loading**
   ```typescript
   // src/core/data-sources/loader.ts
   export class PluginLoader {
     async loadPlugin(path: string): Promise<DataSourcePlugin> {
       const config = await import(`${path}/config.json`);
       const plugin = await import(`${path}/index.ts`);
       return new plugin.default(config);
     }
     
     async loadAllPlugins(): Promise<DataSourcePlugin[]> {
       // Auto-discover and load all plugins
     }
   }
   ```

#### Step 2.4: Update Data Service (Day 6-7)
1. **Create new data service that uses plugins**
   ```typescript
   // src/core/data-sources/service.ts
   export class PluginDataService {
     constructor(
       private registry: DataSourceRegistry,
       private cache: CacheManager
     ) {}
     
     async fetchData(pluginId: string): Promise<GeoJSONFeatureCollection> {
       const plugin = this.registry.get(pluginId);
       if (!plugin) throw new Error(`Plugin ${pluginId} not found`);
       
       return this.cache.getOrFetch(
         pluginId,
         () => plugin.fetchData(),
         plugin.metadata.refreshInterval
       );
     }
   }
   ```

2. **Create compatibility layer for existing hooks**
   ```typescript
   // src/app/hooks/useDataLayerV2.ts
   export function useDataLayerV2<T>(
     layerId: string,
     enabled: boolean,
     refreshInterval?: number
   ) {
     const pluginDataService = usePluginDataService();
     
     // Same interface as existing useDataLayer hook
     // but using new plugin system underneath
   }
   ```

**Phase 2 Testing & Validation**
- TTC data should work identically to before
- New plugin system tested with TTC data
- Performance benchmarks to ensure no regression

---

### Phase 3: CLI Tools & Developer Experience (Week 4)
**Goal**: Create tools to make adding new data sources trivial

#### Step 3.1: Basic CLI Structure (Day 1-2)
1. **Create CLI entry point**
   ```typescript
   // src/tools/cli/index.ts
   #!/usr/bin/env node
   import { Command } from 'commander';
   import { generateDataSource } from './commands/generate';
   import { testDataSource } from './commands/test';
   import { validateAll } from './commands/validate';
   
   const program = new Command();
   
   program
     .name('toronto-pulse')
     .description('Toronto Pulse development tools')
     .version('1.0.0');
   
   program
     .command('generate:datasource')
     .description('Generate a new data source plugin')
     .option('-n, --name <name>', 'Data source name')
     .option('-d, --domain <domain>', 'Data source domain')
     .option('-u, --url <url>', 'API URL')
     .action(generateDataSource);
   
   program
     .command('test:datasource')
     .description('Test a data source plugin')
     .argument('<source>', 'Data source ID')
     .option('--validate', 'Run validation tests')
     .action(testDataSource);
   
   program
     .command('validate:all')
     .description('Validate all data sources')
     .action(validateAll);
   
   program.parse();
   ```

2. **Add CLI to package.json**
   ```json
   {
     "bin": {
       "toronto-pulse": "./dist/tools/cli/index.js"
     },
     "scripts": {
       "build:cli": "tsc --project tsconfig.cli.json",
       "tp": "npm run build:cli && node dist/tools/cli/index.js"
     }
   }
   ```

#### Step 3.2: Data Source Generator (Day 3-4)
1. **Create interactive generator**
   ```typescript
   // src/tools/cli/commands/generate.ts
   import inquirer from 'inquirer';
   import { generatePlugin } from '../generators/plugin-generator';
   
   export async function generateDataSource(options: any) {
     const answers = await inquirer.prompt([
       {
         type: 'input',
         name: 'name',
         message: 'Data source name:',
         default: options.name
       },
       {
         type: 'list',
         name: 'domain',
         message: 'Select domain:',
         choices: ['transportation', 'infrastructure', 'environment', 'events'],
         default: options.domain
       },
       {
         type: 'input',
         name: 'apiUrl',
         message: 'API URL:',
         default: options.url
       },
       {
         type: 'list',
         name: 'apiType',
         message: 'API type:',
         choices: ['json', 'xml', 'csv', 'gtfs']
       },
       {
         type: 'number',
         name: 'refreshInterval',
         message: 'Refresh interval (ms):',
         default: 60000
       }
     ]);
     
     await generatePlugin(answers);
   }
   ```

2. **Create plugin generator**
   ```typescript
   // src/tools/cli/generators/plugin-generator.ts
   export async function generatePlugin(config: PluginConfig) {
     const pluginPath = `src/domains/${config.domain}/${kebabCase(config.name)}`;
     
     // Create directory structure
     await fs.ensureDir(pluginPath);
     
     // Generate config.json
     await generateConfigFile(pluginPath, config);
     
     // Generate plugin files from templates
     await generateFromTemplate('fetcher.ts.template', `${pluginPath}/fetcher.ts`, config);
     await generateFromTemplate('transformer.ts.template', `${pluginPath}/transformer.ts`, config);
     await generateFromTemplate('validator.ts.template', `${pluginPath}/validator.ts`, config);
     await generateFromTemplate('index.ts.template', `${pluginPath}/index.ts`, config);
     await generateFromTemplate('test.spec.ts.template', `${pluginPath}/test.spec.ts`, config);
     
     console.log(`✅ Generated data source: ${config.name}`);
     console.log(`📁 Location: ${pluginPath}`);
     console.log(`🧪 Test with: npm run tp test:datasource ${kebabCase(config.name)}`);
   }
   ```

#### Step 3.3: Testing Framework (Day 5-6)
1. **Create data source testing framework**
   ```typescript
   // src/tools/cli/commands/test.ts
   export async function testDataSource(sourceId: string, options: any) {
     const plugin = await loadPlugin(sourceId);
     
     console.log(`🧪 Testing data source: ${plugin.metadata.name}`);
     
     // Test 1: Configuration validation
     const configValid = validateConfig(plugin);
     console.log(`Config validation: ${configValid ? '✅' : '❌'}`);
     
     // Test 2: API connectivity
     const apiReachable = await testAPIConnectivity(plugin);
     console.log(`API connectivity: ${apiReachable ? '✅' : '❌'}`);
     
     // Test 3: Data fetching
     const dataFetched = await testDataFetching(plugin);
     console.log(`Data fetching: ${dataFetched ? '✅' : '❌'}`);
     
     // Test 4: Data transformation
     const transformedData = await testDataTransformation(plugin);
     console.log(`Data transformation: ${transformedData ? '✅' : '❌'}`);
     
     // Test 5: Data validation
     if (options.validate) {
       const validationResults = await testDataValidation(plugin);
       console.log(`Data validation: ${validationResults.valid ? '✅' : '❌'}`);
       if (!validationResults.valid) {
         console.log(`Validation errors:`, validationResults.errors);
       }
     }
     
     console.log(`\n📊 Test Summary for ${plugin.metadata.name}`);
     // Generate detailed test report
   }
   ```

#### Step 3.4: Auto-Discovery Tools (Day 7)
1. **Toronto Open Data crawler**
   ```typescript
   // src/tools/cli/commands/discover.ts
   export async function discoverTorontoDatasets(domain?: string) {
     const crawler = new TorontoOpenDataCrawler();
     const datasets = await crawler.searchDatasets({
       domain,
       hasGeoData: true,
       isActive: true
     });
     
     console.log(`Found ${datasets.length} datasets:`);
     
     for (const dataset of datasets) {
       console.log(`\n📊 ${dataset.title}`);
       console.log(`   🔗 ${dataset.url}`);
       console.log(`   📝 ${dataset.description}`);
       console.log(`   🏷️  ${dataset.tags.join(', ')}`);
       
       const canAutoGenerate = await checkAutoGenerationSupport(dataset);
       if (canAutoGenerate) {
         console.log(`   ✨ Can auto-generate plugin`);
       }
     }
   }
   ```

**Phase 3 Testing & Validation**
- CLI tools working correctly
- Can generate and test plugins
- Documentation for CLI usage

---

### Phase 4: Migrate Remaining Data Sources (Week 5)
**Goal**: Convert all placeholder data sources to real implementations using new architecture

#### Step 4.1: Bike Share Toronto (Day 1-2)
1. **Research GBFS API**
   - Toronto Bike Share uses GBFS (General Bikeshare Feed Specification)
   - Endpoints: station_information, station_status, system_information
   - Real-time data available

2. **Generate plugin with CLI**
   ```bash
   npm run tp generate:datasource \
     --name="Bike Share Toronto" \
     --domain="transportation" \
     --url="https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information"
   ```

3. **Implement GBFS transformer**
   ```typescript
   // src/core/data-sources/transformers/gbfs.ts
   export class GBFSTransformer implements DataTransformer {
     transform(data: any): GeoJSONFeatureCollection {
       // Convert GBFS format to GeoJSON
     }
   }
   ```

4. **Test and validate**
   ```bash
   npm run tp test:datasource bike-share-toronto --validate
   ```

#### Step 4.2: Road Restrictions (Day 3-4)
1. **Research Toronto Open Data API**
   - Use CKAN API for road restrictions dataset
   - Endpoint: https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/action/datastore_search
   - Resource ID: road-restrictions dataset

2. **Generate and implement plugin**
   ```bash
   npm run tp generate:datasource \
     --name="Road Restrictions" \
     --domain="infrastructure" \
     --url="https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/action/datastore_search"
   ```

3. **Implement CKAN transformer**
   ```typescript
   // src/core/data-sources/transformers/ckan.ts
   export class CKANTransformer implements DataTransformer {
     transform(data: any): GeoJSONFeatureCollection {
       // Convert CKAN format to GeoJSON
     }
   }
   ```

#### Step 4.3: Beach Water Quality (Day 5-6)
1. **Research SOCRATA API**
   - Toronto beaches use SOCRATA format
   - API endpoint: https://secure.toronto.ca/cc_sr_v1/data/edc_geocoded

2. **Generate and implement plugin**
   ```bash
   npm run tp generate:datasource \
     --name="Beach Water Quality" \
     --domain="environment" \
     --url="https://secure.toronto.ca/cc_sr_v1/data/edc_geocoded"
   ```

#### Step 4.4: Update UI Components (Day 7)
1. **Update useDataLayer hook to use new system**
   ```typescript
   // src/app/hooks/useDataLayer.ts
   export function useDataLayer<T extends keyof LayerData>(
     layerId: T,
     enabled: boolean,
     refreshInterval?: number
   ) {
     // Route to new plugin system while maintaining same interface
     return useDataLayerV2(layerId, enabled, refreshInterval);
   }
   ```

2. **Update MapContainer to use plugin registry**
   ```typescript
   // src/app/components/MapContainer.tsx
   const enabledPlugins = useMemo(() => {
     return enabledLayers.map(layer => 
       pluginRegistry.get(layer.id)
     ).filter(Boolean);
   }, [enabledLayers]);
   ```

**Phase 4 Testing & Validation**
- All data sources working with real APIs
- Performance testing with multiple data sources
- UI functionality unchanged from user perspective

---

### Phase 5: Advanced Features & Monitoring (Week 6)
**Goal**: Add observability, feature flags, and advanced plugin capabilities

#### Step 5.1: Monitoring & Observability (Day 1-3)
1. **Create metrics collection**
   ```typescript
   // src/infrastructure/monitoring/metrics.ts
   export class DataSourceMetrics {
     private metrics = new Map<string, SourceMetrics>();
     
     trackFetch(sourceId: string, duration: number, success: boolean): void {
       // Track API call performance
     }
     
     trackDataQuality(sourceId: string, score: number): void {
       // Track data quality metrics
     }
     
     getHealthStatus(sourceId: string): HealthStatus {
       // Return overall health status
     }
     
     generateReport(): MetricsReport {
       // Generate comprehensive metrics report
     }
   }
   ```

2. **Create health checks**
   ```typescript
   // src/infrastructure/monitoring/health-checks.ts
   export class HealthCheckRunner {
     async runHealthChecks(): Promise<HealthReport> {
       const results = await Promise.allSettled([
         this.checkAPIConnectivity(),
         this.checkDataFreshness(),
         this.checkCacheHealth(),
         this.checkMemoryUsage()
       ]);
       
       return this.aggregateResults(results);
     }
   }
   ```

3. **Add monitoring dashboard component**
   ```typescript
   // src/app/components/MonitoringDashboard.tsx
   export function MonitoringDashboard() {
     const metrics = useMetrics();
     const healthStatus = useHealthStatus();
     
     return (
       <div className="monitoring-dashboard">
         {/* Display data source health, performance metrics, etc. */}
       </div>
     );
   }
   ```

#### Step 5.2: Feature Flags System (Day 4-5)
1. **Implement feature flag service**
   ```typescript
   // src/infrastructure/config/feature-flags.ts
   export class FeatureFlagService {
     private flags = new Map<string, FeatureFlag>();
     
     isEnabled(flagKey: string, context?: FeatureFlagContext): boolean {
       const flag = this.flags.get(flagKey);
       if (!flag) return false;
       
       if (flag.rolloutPercentage && flag.rolloutPercentage < 100) {
         return this.shouldShowForUser(flag, context);
       }
       
       return flag.enabled;
     }
     
     private shouldShowForUser(flag: FeatureFlag, context?: FeatureFlagContext): boolean {
       // Implement rollout logic based on user ID hash
     }
   }
   ```

2. **Integrate with data source loading**
   ```typescript
   // Update plugin registry to respect feature flags
   class DataSourceRegistry {
     loadPlugins(): void {
       const plugins = this.discoverPlugins();
       
       for (const plugin of plugins) {
         const flagKey = `data-source-${plugin.metadata.id}`;
         if (this.featureFlags.isEnabled(flagKey)) {
           this.register(plugin);
         }
       }
     }
   }
   ```

#### Step 5.3: Advanced Plugin Features (Day 6-7)
1. **Plugin lifecycle hooks**
   ```typescript
   // Add lifecycle methods to BaseDataSourcePlugin
   export abstract class BaseDataSourcePlugin {
     async onLoad(): Promise<void> {
       // Called when plugin is loaded
     }
     
     async onEnable(): Promise<void> {
       // Called when plugin is enabled
     }
     
     async onDisable(): Promise<void> {
       // Called when plugin is disabled
     }
     
     async onUnload(): Promise<void> {
       // Called when plugin is unloaded
     }
   }
   ```

2. **Plugin dependency system**
   ```typescript
   // Add dependency management
   interface DataSourceMetadata {
     // ... existing fields
     dependencies?: string[];
     conflicts?: string[];
   }
   
   class DependencyResolver {
     resolveDependencies(plugins: DataSourcePlugin[]): DataSourcePlugin[] {
       // Resolve plugin dependencies and conflicts
     }
   }
   ```

3. **Plugin communication system**
   ```typescript
   // Allow plugins to communicate with each other
   export class PluginEventBus {
     emit(event: string, data: any): void;
     on(event: string, handler: (data: any) => void): void;
     off(event: string, handler: (data: any) => void): void;
   }
   ```

**Phase 5 Testing & Validation**
- Monitoring dashboard working correctly
- Feature flags controlling plugin loading
- Advanced plugin features tested

---

### Phase 6: Cleanup & Documentation (Week 7-8)
**Goal**: Remove legacy code, optimize performance, and create comprehensive documentation

#### Step 6.1: Legacy Code Removal (Day 1-2)
1. **Remove old DataService class**
   ```bash
   # Move to deprecated folder first, then delete after validation
   mkdir src/deprecated
   mv src/services/dataService.ts src/deprecated/
   mv src/services/ttcService.ts src/deprecated/
   ```

2. **Update all imports to use new plugin system**
   ```typescript
   // Replace all instances of:
   // import { DataService } from '../services/dataService';
   // With:
   // import { PluginDataService } from '../core/data-sources/service';
   ```

3. **Remove unused configuration files**
   ```bash
   # After validating that layer configs are now generated from plugins
   mv src/config/layers.ts src/deprecated/
   ```

#### Step 6.2: Performance Optimization (Day 3-4)
1. **Bundle analysis and optimization**
   ```bash
   # Add bundle analyzer
   npm install -D webpack-bundle-analyzer
   npm run build && npx webpack-bundle-analyzer dist/assets/*.js
   ```

2. **Lazy loading for plugins**
   ```typescript
   // Implement dynamic imports for plugins
   const plugin = await import(`../domains/${domain}/${pluginId}/index.js`);
   ```

3. **Memory usage optimization**
   ```typescript
   // Implement plugin unloading when not needed
   class PluginManager {
     unloadPlugin(id: string): void {
       const plugin = this.registry.get(id);
       if (plugin) {
         plugin.onUnload();
         this.registry.unregister(id);
       }
     }
   }
   ```

#### Step 6.3: Documentation Creation (Day 5-7)
1. **API Documentation**
   ```bash
   # Generate TypeScript documentation
   npm install -D typedoc
   npx typedoc --out docs/api src/core
   ```

2. **Plugin Development Guide**
   ```markdown
   # docs/plugin-development.md
   # Creating Data Source Plugins
   
   ## Quick Start
   1. Generate plugin: `npm run tp generate:datasource`
   2. Implement fetcher, transformer, validator
   3. Test: `npm run tp test:datasource your-plugin`
   4. Deploy: Add to plugin registry
   
   ## Plugin Structure
   - config.json: Plugin metadata and configuration
   - fetcher.ts: Data fetching logic
   - transformer.ts: Data transformation to GeoJSON
   - validator.ts: Data validation logic
   - index.ts: Main plugin class
   ```

3. **Migration documentation**
   ```markdown
   # docs/migration-guide.md
   # Migration from Legacy to Plugin Architecture
   
   ## For Developers
   - How to migrate existing data sources
   - Breaking changes and migration paths
   - New APIs and patterns
   ```

#### Step 6.4: Final Testing & Validation (Day 8-10)
1. **End-to-end testing**
   ```typescript
   // tests/e2e/full-migration.spec.ts
   describe('Full Migration Validation', () => {
     it('should load all plugins correctly', async () => {
       // Test plugin loading
     });
     
     it('should maintain same user experience', async () => {
       // Test UI functionality
     });
     
     it('should perform at least as well as before', async () => {
       // Performance regression tests
     });
   });
   ```

2. **Load testing**
   ```typescript
   // Test with multiple data sources enabled
   // Measure memory usage, response times, error rates
   ```

3. **Rollback plan validation**
   ```bash
   # Ensure we can quickly rollback if needed
   git tag v1.0.0-pre-migration
   # Document rollback procedure
   ```

---

## Risk Mitigation Strategies

### High-Risk Areas & Mitigations

#### 1. **Data Source Disruption**
- **Risk**: Existing TTC data stops working during migration
- **Mitigation**: 
  - Parallel development approach
  - Keep legacy code until new system is validated
  - Feature flag to switch between old and new systems
  - Rollback plan ready

#### 2. **Performance Regression**
- **Risk**: New architecture is slower than current implementation
- **Mitigation**:
  - Performance benchmarks before migration
  - Load testing at each phase
  - Lazy loading and caching optimizations
  - Memory usage monitoring

#### 3. **Complex Dependencies**
- **Risk**: Plugin system introduces circular dependencies or conflicts
- **Mitigation**:
  - Dependency resolver implementation
  - Clear plugin interfaces
  - Comprehensive testing
  - Gradual rollout

#### 4. **User Experience Impact**
- **Risk**: Users notice negative changes during migration
- **Mitigation**:
  - UI compatibility layer
  - Gradual feature rollout
  - User testing at each phase
  - Easy rollback mechanism

### Rollback Plans

#### Phase-Level Rollbacks
- **Phase 1-2**: Remove new core infrastructure, no user impact
- **Phase 3-4**: Disable new plugins, fall back to legacy DataService
- **Phase 5-6**: Feature flags allow instant rollback to legacy system

#### Emergency Rollback Procedure
1. Set feature flag `use-legacy-data-service=true`
2. Deploy flag change (< 5 minutes)
3. Monitor for error resolution
4. If needed, revert to previous Git tag

---

## Testing Strategy

### Automated Testing
1. **Unit Tests**: All new core classes and plugins
2. **Integration Tests**: Plugin registry, data transformation
3. **E2E Tests**: Full user workflows
4. **Performance Tests**: Load testing, memory usage
5. **Regression Tests**: Ensure no existing functionality breaks

### Manual Testing
1. **Phase validation**: Manual testing after each phase
2. **User acceptance testing**: Real user scenarios
3. **Browser compatibility**: Testing across browsers
4. **Mobile responsiveness**: Testing on mobile devices

### Continuous Validation
1. **Health checks**: Automated monitoring of data sources
2. **Data quality checks**: Validation of incoming data
3. **Performance monitoring**: Response time and memory tracking
4. **Error tracking**: Comprehensive error logging and alerting

---

## Success Metrics

### Technical Metrics
- **Plugin Loading Time**: < 100ms per plugin
- **Memory Usage**: No more than 20% increase
- **API Response Time**: No regression from current performance
- **Error Rate**: < 1% for data fetching operations
- **Cache Hit Rate**: > 80% for repeated requests

### Developer Experience Metrics
- **Time to Add New Data Source**: 
  - Simple source: < 2 hours
  - Complex source: < 2 days
- **Code Reduction**: 50% less code for new data sources
- **Test Coverage**: > 90% for core infrastructure

### Business Metrics
- **Data Source Availability**: > 99.5% uptime
- **User Experience**: No negative user feedback during migration
- **Development Velocity**: 3x faster addition of new data sources

---

## Timeline & Resource Allocation

### Weekly Breakdown
- **Week 1-2**: Core infrastructure (1 developer, full-time)
- **Week 3**: TTC migration (1 developer, full-time)
- **Week 4**: CLI tools (1 developer, full-time)
- **Week 5**: Remaining data sources (1-2 developers)
- **Week 6**: Advanced features (1 developer, full-time)
- **Week 7-8**: Cleanup & documentation (1 developer, part-time)

### Critical Path Items
1. Core plugin system foundation
2. TTC plugin migration and validation
3. CLI tools for development workflow
4. Real API implementations for remaining sources

### Dependencies
- No external dependencies required
- No API changes needed from data providers
- No infrastructure changes required

---

## Post-Migration Benefits

### Immediate Benefits (Week 8+)
- All placeholder data sources replaced with real implementations
- Robust error handling and monitoring
- Feature flag system for safe deployments
- CLI tools for rapid development

### Medium-term Benefits (Month 2-3)
- Addition of 5-10 new data sources using plugin system
- Reduced maintenance overhead
- Better developer onboarding experience
- Improved application performance

### Long-term Benefits (Month 6+)
- Community contributions via plugin system
- Auto-discovery of new Toronto Open Data sources
- Machine learning integration for data quality
- Multi-city expansion using same architecture

---

## Conclusion

This migration plan transforms Toronto Pulse from a monolithic data service architecture to a scalable, plugin-based system while maintaining zero downtime and preserving all existing functionality. The incremental approach ensures low risk while delivering significant long-term benefits for development velocity and system maintainability.

The new architecture will enable rapid addition of new data sources, better developer experience, and a foundation for future enhancements including machine learning, community contributions, and multi-city expansion.
